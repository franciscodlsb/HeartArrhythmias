import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from biosppy import utils
from biosppy import signals
import neurokit2 as nk
import torch

# Initialize Variables
sampling_rate = 500

# Info Files
data_dir = 'ECG_Data/Denoised' # ECG files
Rhythms = pd.read_excel('ECG_Data/RhythmNames.xlsx')
Diagnostics = pd.read_excel('ECG_Data/Diagnostics.xlsx')


# Labels in the Diagnostics file:
Rythm = Diagnostics['Rhythm']
    # Have to be placed in the following group
Rythms_groups = {'SR':['SR', 'SA'], # SA = sinus irregularity, bad label
                 'AFIB':['AF', 'AFIB'], 
                 'GSVT':['SVT','AT', 'AVNRT', 'AVRT', 'SAAWR', 'ST'],
                 'SB':['SB']}
reverse_groups = {val: key for key, values in Rythms_groups.items() for val in values}
    # Create y with groups (On)
y = np.array([reverse_groups.get(i, None) for i in Rythm])
#pd.value_counts(y)



# Function to create X
def ECG_Features(data_dir, sr=500):
        """**Automated feature extraction of ECG signals**

        This function loads every ECG file in the data_dir, and for every channel it performs
        the detection of the R peaks, with this it detects the P, Q, S, T peaks and valleys using
        the biosppy library, it then calculates the mean height, width and prominence for each,
        and the kurtosis, flatline_percentage, skewness and main bands power

        Parameters
        ----------
        data_dir : path where ECG files are located
        sr : sampling rate, int

        Returns
        -------
        X : DataFrame containing all the calculated features for each channel (cols) for all the patients (rows)

    """
    # Get list of files
    patients = os.listdir(data_dir)

    # Allocation of features dataframe
    channels = ['I', 'II', 'III', 'aVR', 'aVL', 'aVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']
    channel_features = [ # H = Height, P = prominence, W = Width
        # QRS Complex
        'mean_H_Q', 'mean_H_R', 'mean_H_S', 'var_H_Q', 'var_H_R', 'var_H_S',
        'mean_P_Q', 'mean_P_R', 'mean_P_S', 'var_P_Q', 'var_P_R', 'var_P_S',
        'mean_W_QRS', 'var_W_QRS',
        #Non QRS
        'mean_H_T', 'var_H_T', 'mean_W_T', 'var_W_T', 'mean_P_T', 'var_P_T',
        'mean_W_nonQRS', 'var_W_nonQRS',
        # Other
        'kurtosis', 'flatline_percentage', 'skewness','Hz0to4', 'Hz4to12', 'Hz12to30']
    combined_features = [f'{channel}_{feature}' for channel in channels 
                        for feature in channel_features]
    X = pd.DataFrame(np.nan, index=range(len(patients)), columns=combined_features)

    # Variables outputs of the biosppy
    outputs_ecg = ('ts', 'filtered', 'rpeaks', 'templates_ts',
                    'templates', 'heart_rate_ts', 'heart_rate')

    outputs_other = (
        'Q_positions', 'Q_start_positions', # Get Q pos
        'S_positions', 'S_end_positions', # Get S Pos
        'T_positions', 'T_start_positions', 'T_end_positions', # Get T pos
        'kurtosis', # kSQI
        'flatline_percentage', # % of signal where the abs value of the dx is lower than threshold
        'skewness', # sSQI
        'Hz0to4', 'Hz4to12', 'Hz12to30') 


    for row, patient in enumerate(patients): # iterate through every patients ecg

        # Load data
        ecg_channels = pd.read_csv(os.path.join(data_dir, patient), header=None, names=channels)

        for channel in channels:
        
            ecg_signal = ecg_channels[channel].to_numpy()

            # Biossppy initial processing
            try:
                ecg_proc = utils.ReturnTuple( # Process ecg: detects R peaks and HR
                    signals.ecg.ecg(ecg_signal, sampling_rate=500, show=False, interactive=False),
                    outputs_ecg).as_dict()
                
                freqs, power = signals.tools.power_spectrum(ecg_signal, 500) # Power spectrum
                
                values = (tuple(ecg_proc.values()) + # Append other values
                    signals.ecg.getQPositions(ecg_proc, show=False) + # Q pos
                    signals.ecg.getSPositions(ecg_proc, show=False) + # S pos
                    signals.ecg.getTPositions(ecg_proc, show=False) + # T pos
                    tuple([signals.ecg.kSQI(ecg_signal)]) + # Kurtosis
                    tuple([signals.ecg.pSQI(ecg_signal, f_thr=0.01)]) + # flatline %
                    tuple([signals.ecg.sSQI(ecg_signal)]) + # skewness
                    tuple(signals.tools.band_power(freqs, power, [0,3.999]).as_dict().values()) +
                    tuple(signals.tools.band_power(freqs, power, [4,11.999]).as_dict().values()) +
                    tuple(signals.tools.band_power(freqs, power, [12,30]).as_dict().values())) 

                ecg_proc = utils.ReturnTuple(values, # Add values to object
                    (outputs_ecg + outputs_other))
            except:
                 continue
            
            # Fill X dataframe
                # kurtosis, flatline, skewness and band power
            for attr in outputs_other[-6:]:
                X.loc[X.index[row], channel + '_' + attr] = ecg_proc[attr]

                # Mean and var H_Q, H_S, H_T, H_R        
            for attr in ['Q_positions', 'S_positions', 'T_positions']:
                X.loc[X.index[row], channel + '_' + attr[0]] = np.nanmean(ecg_signal[ecg_proc[attr]])
                X.loc[X.index[row], channel + '_' + attr[0]] = np.nanvar(ecg_signal[ecg_proc[attr]])
            X.loc[X.index[row], channel + '_mean_H_R'] = np.nanmean(ecg_signal[ecg_proc['rpeaks']])
            X.loc[X.index[row], channel + '_var_H_R'] = np.nanvar(ecg_signal[ecg_proc['rpeaks']])
                
            # Mean_W_QRS and var_W_QRS in ms (1/500*1000)
            X.loc[X.index[row], channel + '_mean_W_QRS'] = np.nanmean((
                ecg_signal[ecg_proc['S_end_positions']] - ecg_signal[ecg_proc['Q_start_positions']])*2)
            X.loc[X.index[row], channel + '_var_W_QRS'] = np.nanvar((
                ecg_signal[ecg_proc['S_end_positions']] - ecg_signal[ecg_proc['Q_start_positions']])*2)

                # Mean_W_nonQRS and var_W_nonQRS, from end of S till the start of the next Q in ms
            nonQRS_intervals = np.array([ecg_proc['S_end_positions'][i] - ecg_proc['Q_start_positions'][i+1]
                                for i in range(len(ecg_proc['T_end_positions'])-1)])*2
            X.loc[X.index[row], channel + '_mean_W_nonQRS'] = np.nanmean(nonQRS_intervals)
            X.loc[X.index[row], channel + '_var_W_nonQRS'] = np.nanvar(nonQRS_intervals)

                # Mean_W_T and var_W_T in ms
            X.loc[X.index[row], channel + '_mean_W_T'] = np.nanmean((
                ecg_signal[ecg_proc['T_end_positions']] - ecg_signal[ecg_proc['T_start_positions']])*2)
            X.loc[X.index[row], channel + '_var_W_T'] = np.nanvar((
                ecg_signal[ecg_proc['T_end_positions']] - ecg_signal[ecg_proc['T_start_positions']])*2)

                # Mean and var prominence for Q, R, S, T,  and then mean or average
                # Q
            Q_Ps = np.nanmin(np.stack([ # substract closests countours, mix in array, calculate min of each diff
                ecg_signal[ecg_proc['Q_positions']]-ecg_signal[ecg_proc['rpeaks']],
                ecg_signal[ecg_proc['Q_positions']]-ecg_signal[ecg_proc['Q_start_positions']] ]),
                axis = 0)
            X.loc[X.index[row], channel + '_mean_P_Q'] = np.nanmean(Q_Ps)
            X.loc[X.index[row], channel + '_var_P_Q'] = np.nanvar(Q_Ps)
                # R
            R_Ps = np.nanmin(np.stack([
                ecg_signal[ecg_proc['rpeaks']]-ecg_signal[ecg_proc['Q_positions']],
                ecg_signal[ecg_proc['rpeaks']]-ecg_signal[ecg_proc['S_positions']] ]),
                axis = 0)
            X.loc[X.index[row], channel + '_mean_P_R'] = np.nanmean(R_Ps)
            X.loc[X.index[row], channel + '_var_P_R'] = np.nanvar(R_Ps)
                #S
            S_Ps = np.nanmin(np.stack([
                ecg_signal[ecg_proc['S_positions']]-ecg_signal[ecg_proc['rpeaks']],
                ecg_signal[ecg_proc['S_positions']]-ecg_signal[ecg_proc['S_end_positions']] ]),
                axis = 0)
            X.loc[X.index[row], channel + '_mean_P_S'] = np.nanmean(S_Ps)
            X.loc[X.index[row], channel + '_var_P_S'] = np.nanvar(S_Ps)
                # T
            T_Ps = np.nanmin(np.stack([ 
                ecg_signal[ecg_proc['T_positions']]-ecg_signal[ecg_proc['T_end_positions']],
                ecg_signal[ecg_proc['T_positions']]-ecg_signal[ecg_proc['T_start_positions']] ]),
                axis = 0)
            X.loc[X.index[row], channel + '_mean_P_T'] = np.nanmean(T_Ps)
            X.loc[X.index[row], channel + '_var_P_T'] = np.nanvar(T_Ps)



    '''
        _, rpeaks = nk.ecg_peaks(ecg_signal, sampling_rate=sr, method='neurokit')
        _, waves_peak = nk.ecg_delineate(ecg_signal, rpeaks, sampling_rate=sr, method="dwt")
        waves_peak['ECG_R_Peaks'] = rpeaks['ECG_R_Peaks'] # Add R peaks
        waves_peak = {k:np.array(v) for k, v in waves_peak.items()} # Convert to numpy

        # Extract features for non QRS Peaks
        mean_height_P = np.nanmean(waves_peak['ECG_P_Peaks'])
        var_height_P = np.nanvar(waves_peak['ECG_P_Peaks'])
        mean_width_P = np.nanmean(waves_peak['ECG_P_Offsets'] - waves_peak['ECG_P_Onsets']) * 1/sr*1000
        var_width_P = np.nanvar((waves_peak['ECG_P_Offsets'] - waves_peak['ECG_P_Onsets']) * 1/sr*1000)

            # Approximate prominence: vertical distance between the peak and its lowest contour line
        P_offsets_values = ecg_signal[waves_peak['ECG_P_Offsets'][~np.isnan(waves_peak['ECG_P_Offsets'])].astype(int)]
        P_onsets_values = ecg_signal[waves_peak['ECG_P_Onsets'][~np.isnan(waves_peak['ECG_P_Onsets'])].astype(int)]
        P_lowest_contours = np.min(np.column_stack([P_offsets_values, P_onsets_values]), axis=1)
        P_prominences = waves_peak['ECG_P_Peaks'][~np.isnan(waves_peak['ECG_P_Peaks'])] - P_lowest_contours
        P_mean_promincence = np.nanmean(waves_peak['ECG_P_Peaks'] - ~np.isnan(waves_peak['ECG_P_Peaks']))
        P_var_promincence = np.nanvar(waves_peak['ECG_P_Peaks'] - ~np.isnan(waves_peak['ECG_P_Peaks']))
    '''

    return X

X =  pd.concat([Diagnostics.drop(columns=['Rhythm', 'Beat']), X]).drop_duplicates().reset_index(drop=True)

X.to_csv('ECG_Data/X.csv')